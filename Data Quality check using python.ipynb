{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e1beae",
   "metadata": {},
   "source": [
    "1. Data Ingestion from a Database (PostgreSQL Example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd004d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='data_ingestion.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "try:\n",
    "    # Database connection configuration\n",
    "    db_config = {\n",
    "        'user': 'your_username',\n",
    "        'password': 'your_password',\n",
    "        'host': 'localhost',\n",
    "        'port': '5432',\n",
    "        'database': 'your_database'\n",
    "    }\n",
    "\n",
    "    # Create a database connection\n",
    "    engine = create_engine(f'postgresql://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:{db_config[\"port\"]}/{db_config[\"database\"]}')\n",
    "\n",
    "    # SQL query to fetch data\n",
    "    query = \"SELECT * FROM your_table\"\n",
    "\n",
    "    # Read data from the database into a DataFrame\n",
    "    data = pd.read_sql(query, engine)\n",
    "\n",
    "    # Display the first few rows of the data\n",
    "    print(data.head())\n",
    "\n",
    "    logging.info(\"Data ingestion completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    error_message = f\"Error during data ingestion: {str(e)}\"\n",
    "    logging.error(error_message)\n",
    "    print(error_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35115043",
   "metadata": {},
   "source": [
    "2. ETL Process with Detailed Logging, Exception Handling, and Data Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='etl_process.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "try:\n",
    "    # Read source data from a CSV file\n",
    "    source_data = pd.read_csv(\"source_data.csv\")\n",
    "\n",
    "    # Check data validity\n",
    "    if not source_data.empty:\n",
    "        # Perform complex data transformations\n",
    "        transformed_data = source_data.groupby(['category', 'date']).agg({\n",
    "            'value1': 'sum',\n",
    "            'value2': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # Save transformed data to a new CSV file\n",
    "        transformed_data.to_csv(\"transformed_data.csv\", index=False)\n",
    "\n",
    "        logging.info(\"ETL process completed successfully.\")\n",
    "    else:\n",
    "        logging.error(\"Source data is empty.\")\n",
    "        print(\"Source data is empty.\")\n",
    "\n",
    "except Exception as e:\n",
    "    error_message = f\"ETL process failed with error: {str(e)}\"\n",
    "    logging.error(error_message)\n",
    "    print(error_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8308c9",
   "metadata": {},
   "source": [
    "3. Data Quality Checks with Detailed Logging, Exception Handling, and Data Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaa860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='data_quality.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "try:\n",
    "    # Read data from CSV file\n",
    "    data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "\n",
    "    if missing_values.any():\n",
    "        logging.warning(\"Missing values found:\")\n",
    "        logging.warning(missing_values)\n",
    "        print(\"Warning: Missing values found. Check the log file for details.\")\n",
    "    else:\n",
    "        logging.info(\"No missing values.\")\n",
    "        print(\"No missing values.\")\n",
    "\n",
    "except Exception as e:\n",
    "    error_message = f\"Data quality check failed with error: {str(e)}\"\n",
    "    logging.error(error_message)\n",
    "    print(error_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f8f55",
   "metadata": {},
   "source": [
    "In these scripts:\n",
    "\n",
    "I use try-except blocks to gracefully handle exceptions and log any errors that occur.\n",
    "Logging is configured to record important information, warnings, and errors in separate log files for each task.\n",
    "Data validation checks are included to ensure the data's integrity and validity.\n",
    "Detailed comments and variable names help clarify each step of the process.\n",
    "Exception handling ensures that errors are captured and reported.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
